<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Supported solvers · PolynomialOptimization.jl</title><meta name="title" content="Supported solvers · PolynomialOptimization.jl"/><meta property="og:title" content="Supported solvers · PolynomialOptimization.jl"/><meta property="twitter:title" content="Supported solvers · PolynomialOptimization.jl"/><meta name="description" content="Documentation for PolynomialOptimization.jl."/><meta property="og:description" content="Documentation for PolynomialOptimization.jl."/><meta property="twitter:description" content="Documentation for PolynomialOptimization.jl."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">PolynomialOptimization.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li><a class="tocitem" href="guide.html">Walkthrough</a></li><li><a class="tocitem" href="reference.html">Reference</a></li><li class="is-active"><a class="tocitem" href="includedsolvers.html">Supported solvers</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Packaged-solvers"><span>Packaged solvers</span></a></li><li><a class="tocitem" href="#Loraine"><span>Loraine</span></a></li><li><a class="tocitem" href="#LoRADS"><span>LoRADS</span></a></li><li><a class="tocitem" href="#SketchyCGAL"><span>SketchyCGAL</span></a></li><li><a class="tocitem" href="#SpecBM"><span>SpecBM</span></a></li><li><a class="tocitem" href="#LANCELOT"><span>LANCELOT</span></a></li></ul></li><li><a class="tocitem" href="backend.html">Backend</a></li><li><a class="tocitem" href="auxreference.html">Reference of auxilliaries</a></li><li><a class="tocitem" href="intpolynomials.html">IntPolynomials</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="includedsolvers.html">Supported solvers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="includedsolvers.html">Supported solvers</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/projekter/PolynomialOptimization.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/projekter/PolynomialOptimization.jl/blob/main/docs/src/includedsolvers.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="solvers_poly_optimize"><a class="docs-heading-anchor" href="#solvers_poly_optimize">Supported solvers</a><a id="solvers_poly_optimize-1"></a><a class="docs-heading-anchor-permalink" href="#solvers_poly_optimize" title="Permalink"></a></h1><p>The following list contains all the solvers and the required packages that provide access to the solver. A solver of name <code>X</code> will always provide at least one of the two methods <code>:XSOS</code> or <code>:XMoment</code>. The former models the sum-of-squares formulation of the problem - each monomial corresponds to one constraint, and the solution comes from the dual vector. The latter models the Lasserre moment hierarchy of the problem - each monomial corresponds to a primal variable. Which method (or both) is offered by the solver depends on the particular interface that is supported by the solver and which form fits more naturally to this interface. Every solver will also provide an alias <code>:X</code> method that defaults to the recommended method for this solver. The given performance indicators are merely based on experience and may not be accurate for your particular problem. In particular the maximally recommended basis size depends heavily on the structure of the final problem, which can easily put the number up or down by 100 or more. All solvers may expose options that can influence the runtime behavior.</p><table><tr><th style="text-align: right">Solver</th><th style="text-align: center">Package</th><th style="text-align: center">License</th><th style="text-align: center">Methods</th><th style="text-align: center">Speed</th><th style="text-align: center">Accuracy</th><th style="text-align: center">Memory</th><th style="text-align: left">max. recomm. basis size</th></tr><tr><td style="text-align: right">Clarabel</td><td style="text-align: center"><a href="https://github.com/oxfordcontrol/Clarabel.jl">Clarabel.jl</a></td><td style="text-align: center">Apache</td><td style="text-align: center">moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍</td><td style="text-align: left">~200</td></tr><tr><td style="text-align: right">COPT</td><td style="text-align: center"><a href="https://github.com/COPT-Public/COPT.jl/tree/main">COPT.jl</a></td><td style="text-align: center">commercial</td><td style="text-align: center">moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left">~700</td></tr><tr><td style="text-align: right">Hypatia<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup></td><td style="text-align: center"><a href="https://github.com/jump-dev/Hypatia.jl">Hypatia.jl</a></td><td style="text-align: center">MIT</td><td style="text-align: center">moment</td><td style="text-align: center">👍👍</td><td style="text-align: center">👍👍</td><td style="text-align: center">👍</td><td style="text-align: left">~100</td></tr><tr><td style="text-align: right">LANCELOT<sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup></td><td style="text-align: center"><a href="https://github.com/ralna/GALAHAD/tree/master/GALAHAD.jl">GALAHAD.jl</a></td><td style="text-align: center">BSD</td><td style="text-align: center">nonlinear</td><td style="text-align: center">n.a.</td><td style="text-align: center">n.a.</td><td style="text-align: center">👍👍👍</td><td style="text-align: left">n.a.</td></tr><tr><td style="text-align: right">Loraine</td><td style="text-align: center">∅<sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup></td><td style="text-align: center">MIT</td><td style="text-align: center">primal moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left">moderately large</td></tr><tr><td style="text-align: right">LoRADS</td><td style="text-align: center"><a href="https://github.com/COPT-Public/LoRADS">LoRADS</a><sup class="footnote-reference"><a id="citeref-4" href="#footnote-4">[4]</a></sup></td><td style="text-align: center">MIT</td><td style="text-align: center">primal moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left">very large</td></tr><tr><td style="text-align: right">Mosek<sup class="footnote-reference"><a id="citeref-5" href="#footnote-5">[5]</a></sup></td><td style="text-align: center"><a href="https://github.com/MOSEK/Mosek.jl">Mosek.jl</a></td><td style="text-align: center">commercial</td><td style="text-align: center">SOS, moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍</td><td style="text-align: left">~300 - 500</td></tr><tr><td style="text-align: right">ProxSDP</td><td style="text-align: center"><a href="https://github.com/mariohsouto/ProxSDP.jl">ProxSDP.jl</a></td><td style="text-align: center">MIT</td><td style="text-align: center">primal moment</td><td style="text-align: center">👍👍👍</td><td style="text-align: center">👍👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left">very large</td></tr><tr><td style="text-align: right">SCS</td><td style="text-align: center"><a href="https://github.com/jump-dev/SCS.jl">SCS.jl</a></td><td style="text-align: center">MIT</td><td style="text-align: center">moment</td><td style="text-align: center">👍</td><td style="text-align: center">👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">SketchyCGAL</td><td style="text-align: center">∅</td><td style="text-align: center">MIT</td><td style="text-align: center">primal moment</td><td style="text-align: center">👎</td><td style="text-align: center">👍</td><td style="text-align: center">👍👍👍</td><td style="text-align: left"></td></tr><tr><td style="text-align: right">SpecBM</td><td style="text-align: center">∅<sup class="footnote-reference"><a id="citeref-6" href="#footnote-6">[6]</a></sup></td><td style="text-align: center">MIT</td><td style="text-align: center">SOS</td><td style="text-align: center">n.a.</td><td style="text-align: center">n.a.</td><td style="text-align: center">👍👍👍</td><td style="text-align: left"></td></tr></table><h1 id="Packaged-solvers"><a class="docs-heading-anchor" href="#Packaged-solvers">Packaged solvers</a><a id="Packaged-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Packaged-solvers" title="Permalink"></a></h1><p>During the development of this package, several interesting solvers were proposed in research. The ones that were implemented are documented on this page. They can be accessed from the <code>PolynomialOptimization.Solvers</code> submodule.</p><h2 id="Loraine"><a class="docs-heading-anchor" href="#Loraine">Loraine</a><a id="Loraine-1"></a><a class="docs-heading-anchor-permalink" href="#Loraine" title="Permalink"></a></h2><p>The Loraine solver is suiteable for large-scale low-rank semidefinite programming. Note that the implementation provided by <code>PolynomialOptimization</code> supports only a subset of Loraine&#39;s features (but this much more efficiently): the direct solver is not available, data matrices are assumed not to be rank-one and always sparse.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.Loraine.Model" href="#PolynomialOptimization.Solvers.Loraine.Model"><code>PolynomialOptimization.Solvers.Loraine.Model</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Model(; A, C, b, [c_lin, A_lin,] coneDims, check=true)</code></pre><p>Constructs a model for <code>PolynomialOptimization</code>&#39;s rewrite of the Loraine solver. This solves the problem</p><p class="math-container">\[    \min \vec c_{\mathrm{lin}} \cdot \vec x + \sum_j \langle C_j, X_j\rangle \\
    \text{such that} \\
    x_i \geq 0 \ \forall i \\
    X_j \succeq 0 \forall j \\
    A_{\mathrm{lin}, k} \cdot \vec x + \sum_j \langle \operatorname{mat}(A_{k, j}), X_k\rangle = b_k \ \forall k\]</p><p>with the following representation in the variables:</p><ul><li><code>1 ≤ j ≤ length(coneDims) = length(A) = length(C)</code></li><li><code>A</code> is a vector of <code>SparseMatricCSC</code>s, where every matrix corresponds to a semidefinite optimization variable. Each row in the matrix corresponds to one constraint; when the row is reshaped into a matrix in a col-major order (which must then be symmetric), it defines the coefficient matrix <span>$\operatorname{mat}(A_{k, j})$</span>. The side dimension of the matrix is stored in <code>coneDims</code>.</li><li>If present, <code>c_lin</code> is a <code>SparseVector</code> and <code>A_lin</code> a <code>SparseMatrixCSC</code> that define the objective and constraints coefficients for the nonnegative variables. They may be omitted only together.</li></ul><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.Loraine.Solver"><code>Solver</code></a>, <a href="includedsolvers.html#PolynomialOptimization.Solvers.Loraine.solve!"><code>solve!</code></a>.</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>This function checks the validity of the variables; however, it is quite expensive to do the checks for symmetry. They can be disabled by setting <code>check</code> to <code>false</code>.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/Loraine/DataTypes.jl#L14-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.Loraine.Preconditioner" href="#PolynomialOptimization.Solvers.Loraine.Preconditioner"><code>PolynomialOptimization.Solvers.Loraine.Preconditioner</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Preconditioner</code></pre><ul><li><em>per CG iteration</em>, <code>PRECONDITIONER_NONE</code> is faster (lower complexity) than <code>PRECONDITIONER_HBETA</code> which is faster than <code>PRECONDITIONER_HALPHA</code></li><li><em>as a preconditioner</em>, <code>PRECONDITIONER_HALPHA</code> is better than <code>PRECONDITIONER_HBETA</code> is better than <code>PRECONDITIONER_NONE</code>, in the sense of CG iterations needed to solve the linear system</li><li>some SDP problems are &quot;easy&quot;, meaning that CG always converges without preconditioner (i.e., <code>preconditioner = PRECONDITIONER_NONE</code>), so it&#39;s always worth trying this option</li><li><code>PRECONDITIONER_HYBRID</code> starts with (cheaper) <code>H_beta</code> and once it gets into difficulties, switches to <code>H_alpha</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/Loraine/Enums.jl#L7-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.Loraine.Solver" href="#PolynomialOptimization.Solvers.Loraine.Solver"><code>PolynomialOptimization.Solvers.Loraine.Solver</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Solver(model; tol_cg=0.01, tol_cg_up=0.5, tol_cg_min=1e-7, eDIMACS=1e-7,
    preconditioner=PRECONDITIONER_HALPHA, erank=1, aamat=AMAT_DIAGAᵀA, fig_ev=0,
    verb=VERBOSITY_SHORT, initpoint=INITPOINT_LORAINE, maxit=100)</code></pre><p>Defines a solver for a previously defined model. Only the iterative conjugate gradient method is implemented.</p><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.Loraine.Model"><code>Model</code></a>, <a href="includedsolvers.html#PolynomialOptimization.Solvers.Loraine.solve!"><code>solve!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/Loraine/DataTypes.jl#L138-L146">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.Loraine.solve!" href="#PolynomialOptimization.Solvers.Loraine.solve!"><code>PolynomialOptimization.Solvers.Loraine.solve!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve!(solver)</code></pre><p>Solves a freshly initialized solver. Note that calling this function twice will produce the same results (unless parameters are changed), as the initial state is always restored at the beginning of the call.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/Loraine/Loraine.jl#L21-L26">source</a></section></article><h2 id="LoRADS"><a class="docs-heading-anchor" href="#LoRADS">LoRADS</a><a id="LoRADS-1"></a><a class="docs-heading-anchor-permalink" href="#LoRADS" title="Permalink"></a></h2><p>The experimental LoRADS solver is suitable for large-scale low-rank semidefinite programming. Note that it is currently in a very early stage of development and not yet very customizable. In particular, at the time of writing, it is not possible to configure the tolerance of the termination criterion, which is always set to <span>$10^{-5}$</span>. There is also no interface defined to extract the solution data; <code>PolynomialOptimization</code> relies on the internal representation of the state to access this information. Note that this is likely to change in a new version; the supported solver version is a patched version of <code>1.0.0</code>. You will also see a lot of solver output, regardless of the <code>verbose</code> flag, as this cannot be turned off. LoRADS has to be compiled from the source into a shared library; its path must then be provided to the package using <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.set_solverlib"><code>set_solverlib</code></a>. This setting will take effect after the Julia session is restarted.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.set_solverlib" href="#PolynomialOptimization.Solvers.LoRADS.set_solverlib"><code>PolynomialOptimization.Solvers.LoRADS.set_solverlib</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_solverlib(path)</code></pre><p>Changes the path to the LoRADS library, which takes effect after restarting Julia.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L32-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.Solver" href="#PolynomialOptimization.Solvers.LoRADS.Solver"><code>PolynomialOptimization.Solvers.LoRADS.Solver</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Solver()</code></pre><p>Creates a new empty LoRADS solver object. This has to be initialized by called <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.init_solver"><code>init_solver</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/DataTypes.jl#L269-L273">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.ConeType" href="#PolynomialOptimization.Solvers.LoRADS.ConeType"><code>PolynomialOptimization.Solvers.LoRADS.ConeType</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ConeType</code></pre><p>The type of the current cone. Only <code>CONETYPE_DENSE_SDP</code> and <code>CONETYPE_SPARSE_SDP</code> are implemented.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/Enums.jl#L17-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.init_solver" href="#PolynomialOptimization.Solvers.LoRADS.init_solver"><code>PolynomialOptimization.Solvers.LoRADS.init_solver</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">init_solver(solver, nConstrRows, coneDims::AbstractVector{LoRADSInt}, nLpCols)</code></pre><p>Initializes a fresh <code>Solver</code> object with <code>nConstrRows</code> constraints, positive semidefinite variables of side dimension <code>coneDims</code> (a vector of integers), and <code>nLpCols</code> scalar nonnegative variables.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L50-L55">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.set_dual_objective" href="#PolynomialOptimization.Solvers.LoRADS.set_dual_objective"><code>PolynomialOptimization.Solvers.LoRADS.set_dual_objective</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_dual_objective(solver, dObj::AbstractVector{Cdouble})</code></pre><p>Sets the dual objective, i.e., the right-hand side of the constraints, in an initialized <code>Solver</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L102-L106">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata" href="#PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata"><code>PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">conedata_to_userdata(cone::ConeType, nConstrRows, dim,
    coneMatBeg::AbstractVector{LoRADSInt}, coneMatIdx::AbstractVector{LoRADSInt},
    coneMatElem::AbstractVector{Cdouble})</code></pre><p>Allocates a new user data objects and sets its conic data. This consists of a cone type (only <code>CONETYPE_DENSE_SDP</code> and <code>CONETYPE_SPARSE_SDP</code> are supported), the number of rows (which is the same as the number of constraints in the solver) and the side dimension of the semidefinite variable, followed by the constraint matrices in zero-indexed CSR format. Every row corresponds to the vectorized lower triangle of the column of a constraint matrix. The zeroth row is the coefficient matrix for the objective. Therefore, <code>nConstrRows +1 = length(coneMatBeg) -1</code> should hold (<code>+1</code> for the objective; <code>-1</code> for CSR).</p><p>The returned userdata pointer should be assigned to a solver, which will take care of freeing the allocated data. Note that the vectors passed to this function must be preserved until the <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.preprocess"><code>preprocess</code></a> function was called, after which they can be freed.</p><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.set_cone"><code>set_cone</code></a>, <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.init_cone_data"><code>init_cone_data</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L113-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.set_cone" href="#PolynomialOptimization.Solvers.LoRADS.set_cone"><code>PolynomialOptimization.Solvers.LoRADS.set_cone</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_cone(solver, iCone, userCone)</code></pre><p>Sets the <code>iCone</code>th cone to the data previously defined using <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata"><code>conedata_to_userdata</code></a>.</p><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.init_cone_data"><code>init_cone_data</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L147-L153">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.set_lp_cone" href="#PolynomialOptimization.Solvers.LoRADS.set_lp_cone"><code>PolynomialOptimization.Solvers.LoRADS.set_lp_cone</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">set_lp_cone(solver, nConstrRows, nLpCols, lpMatBeg::AbstractVector{LoRADSInt},
    lpMatIdx::AbstractVector{LoRADSInt}, lpMatElem::AbstractVector{Cdouble})</code></pre><p>Set the data of the constraint matrix for the linear variables according to the CSR data specified in the parameters.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This function is not exported on the original code release and can therefore not be used. However, only the patched version should be used, as it fixes heap corruption errors that can arise during the optimization.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L159-L168">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.init_cone_data" href="#PolynomialOptimization.Solvers.LoRADS.init_cone_data"><code>PolynomialOptimization.Solvers.LoRADS.init_cone_data</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">init_cone_data(solver, coneMat, coneDims, lpMat)</code></pre><p>Initializes the solver for a problem in the form</p><p class="math-container">\[   \min \vec a_0 \cdot \vec x + \sum_j \langle\operatorname{mat}(G_{j, 0}), Z_j\rangle \\
   \text{such that} \\
   x_i \geq 0 \ \forall i \\
   Z_j \succeq 0 \ \forall j \\
   \vec a_k \cdot \vec x - \sum_j \langle\operatorname{mat}(G_{j, k}, Z_j)\rangle = c_k \ \forall k\]</p><p>with the following representation in the variables:</p><ul><li><code>1 ≤ j ≤ length(coneDims) = length(coneMat)</code></li><li><code>coneMat</code> is a vector of matrices, <code>lpMat</code> is a matrix. They should be in CSR storage, where the row index (starting at 0 for the objective, then <code>k</code> for the <code>k</code>th constraint) is the constraint. Since CSR is not natively supported by Julia, the transpose of a <code>SparseMatrixCSC{Cdouble,LoRADSInt}</code> is expected.</li><li><code>mat</code> makes the unscaled lower triangle into a full matrix</li></ul><p>This is a convenience function that does the job of <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata"><code>conedata_to_userdata</code></a>, <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.set_cone"><code>set_cone</code></a>, and <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.preprocess"><code>preprocess</code></a> in one step. However, note that it is more efficient to call these functions individually.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L183-L203">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.preprocess" href="#PolynomialOptimization.Solvers.LoRADS.preprocess"><code>PolynomialOptimization.Solvers.LoRADS.preprocess</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">preprocess(solver, coneDims::AbstractVector{LoRADSInt})</code></pre><p>Invokes the preprocessor. This should be called after all cones were set up, after which their original data may be reused or destroyed.</p><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.conedata_to_userdata"><code>conedata_to_userdata</code></a>, <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.set_cone"><code>set_cone</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L275-L282">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.load_sdpa" href="#PolynomialOptimization.Solvers.LoRADS.load_sdpa"><code>PolynomialOptimization.Solvers.LoRADS.load_sdpa</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">load_sdpa(fn)</code></pre><p>Loads a problem from a file <code>fn</code> in SDPA format and returns a preprocessed <code>Solver</code> instance, a vector containing the cone dimensions, and the number of nonnegative scalar variables.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This function will produce memory leaks. The data that is allocated by the LoRADS library cannot be freed by Julia, as no corresponding functions are exported. Only use it for quick tests, not in production.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L430-L439">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.solve" href="#PolynomialOptimization.Solvers.LoRADS.solve"><code>PolynomialOptimization.Solvers.LoRADS.solve</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve(solver, params, coneDims)</code></pre><p>Solves a preprocessed <code>Solver</code> instance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L497-L501">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.get_X" href="#PolynomialOptimization.Solvers.LoRADS.get_X"><code>PolynomialOptimization.Solvers.LoRADS.get_X</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_X(solver, i)</code></pre><p>Returns the <code>i</code>th PSD solution matrix <span>$X_i$</span>. The result will be a freshly allocated symmetric view of a dense matrix.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This method may only be called once per <code>i</code>. All further calls with the same <code>i</code> will give wrong output, as the internal solver data is modified.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L643-L651">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.get_Xlin" href="#PolynomialOptimization.Solvers.LoRADS.get_Xlin"><code>PolynomialOptimization.Solvers.LoRADS.get_Xlin</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_Xlin(solver)</code></pre><p>Returns the linear solution vector <span>$x$</span>. The result will be a vector backed by internal solver data and will be invalidated if the solver is destroyed. Copy it if desired.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This method may only be called once. All further calls will give wrong output, as the internal solver data is modified.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L667-L675">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.get_S" href="#PolynomialOptimization.Solvers.LoRADS.get_S"><code>PolynomialOptimization.Solvers.LoRADS.get_S</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_S(solver, i)</code></pre><p>Returns the <code>i</code>th slack variable for the PSD solution matrix <span>$S_i$</span>. The result will be a freshly allocated symmetric view of a dense matrix.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L686-L691">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LoRADS.get_Slin" href="#PolynomialOptimization.Solvers.LoRADS.get_Slin"><code>PolynomialOptimization.Solvers.LoRADS.get_Slin</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_Slin(solver[, i::AbstractUnitRange])</code></pre><p>Returns the slack variables to the nonnegative variables of index <code>i</code> (by default, all). The result will be a freshly allocated vector.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/LoRADS/LoRADS.jl#L711-L716">source</a></section></article><h2 id="SketchyCGAL"><a class="docs-heading-anchor" href="#SketchyCGAL">SketchyCGAL</a><a id="SketchyCGAL-1"></a><a class="docs-heading-anchor-permalink" href="#SketchyCGAL" title="Permalink"></a></h2><p>While the solver was implemented for the purpose of being used within <code>PolynomialOptimization</code>, it also works as a standalone routine (and could in principle be a separate package). <a href="https://doi.org/10.1137/19M1305045">SketchyCGAL</a> is a solver that scales very well for large problem sizes by maintaining a sketch of the semidefinite matrices based on the assumption that the optimal solution has low rank; indeed, in polynomial optimizations, if there is an optimal point for the problem that can be encoded in the chosen basis, then this automatically gives rise to a rank-one semidefinite encoding of this point.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.SketchyCGAL.sketchy_cgal" href="#PolynomialOptimization.Solvers.SketchyCGAL.sketchy_cgal"><code>PolynomialOptimization.Solvers.SketchyCGAL.sketchy_cgal</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sketchy_cgal(A, b, C; α=(0, 1), rank, ϵ=1e-4, max_iter=0, time_limit=0, verbose=false,
    β₀=1, K=∞, method=:auto, callback=(_) -&gt; ()[, A_norm][, A_normsquare])</code></pre><p>Enhanced implementation of the <a href="https://doi.org/10.1137/19M1305045">SketchyCGAL algorithm</a>. This solves the following problem:</p><p class="math-container">\[    \min \bigl\{
        \sum_i \operatorname{tr}(C_i X_i) :
            \sum_i \operatorname{tr}(A_{j, i} X_i) = b_j \ \forall j,
            \alpha_1 \leq \sum_i \operatorname{tr}(X_i) \leq \alpha_2,
            X_i \succeq 0 \ \forall i
    \bigr\}\]</p><p>The function returns the optimization status, objective value, and the optimal matrix <span>$X$</span> (in the form of an <code>Eigen</code> factorization object).</p><p><strong>Parameters</strong></p><ul><li><code>A</code> is an <code>AbstractMatrix</code> whose entries are of type <code>AbstractMatrix</code> themselves. Alternatively, <code>A</code> can also be an <code>AbstractVector</code> of <code>AbstractMatrices</code>; in this case, <span>$A_{j, i}$</span> is given by taking the matrix <code>A[i]</code> and reshaping its columns into a square matrix.</li><li><code>b</code> is an <code>AbstractVector</code> of real numbers</li><li><code>C</code> is an <code>AbstractVector</code> whose entries are of type <code>AbstractMatrix</code> themselves</li><li><code>α</code> is a 2-tuples of nonnegative numbers, where the numbers defines the bounds on the sum of all traces</li><li><code>rank</code> controls the rank that is used to approximate the end result. It might either be an integer, which then puts the same rank constraint on all <span>$X_i$</span>, or a tuple/vector of integers, which allows to specify different rank constraints.</li><li>The solution accuracy can be controlled by the parameter <code>ϵ</code>; however, no more than <code>max_iter</code> iterations are carried out, and no more iterations will be performed if <code>time_limit</code> was exceeded (in seconds), regardless of <code>ϵ</code>. Set any of those three parameters to zero to disable the check.</li><li>The <code>callback</code> may be called after each iteration and will receive a <a href="includedsolvers.html#PolynomialOptimization.Solvers.SketchyCGAL.Status"><code>Status</code></a> as parameter. If the callback returns <code>false</code>, the iteration will be the last one.</li><li>The parameters <code>β₀</code> and <code>K</code> allow to tune the optimization. <code>β₀</code> is a smoothing, <code>K</code> limits the dual vector to a generalized sphere of radius <code>K</code> around the origin.</li><li>The <code>method</code> determines the way in which the smallest eigenvalue and its eigenvector are calculated during each iteration. Possible values are (this might also be a vector/tuple, to specify the method for each <span>$X_i$</span>)<ul><li><code>:lanczos_space</code> (uses the space-efficient implementation described in the SketchyCGAL paper, memory is linear in the problem size)</li><li><code>:lanczos_time</code> (uses the same principle, but can save about half of the operations by using more memory: quadratic in the problem size)</li><li><code>:lobpcg_fast</code> (uses the LOBPCG solver from the <a href="https://iterativesolvers.julialinearalgebra.org/dev/"><code>IterativeSolvers</code></a> package, bounding the number of iterations with the same heuristic as for the Lanczos methods)</li><li><code>:lobpcg_accurate</code> (bounds the error instead to <code>ϵ/100</code>)</li><li><code>:auto</code> chooses <code>:lobpcg_accurate</code> for problem sizes smaller than 10, <code>:lanczos_time</code> for problem sizes less than 11500 (where roughly 1 GiB is required for the speedup), and <code>:lanczos_space</code> for all larger problems.</li></ul></li><li><code>A_normsquare</code> (or <code>A_norm</code>) is supposed to hold the sum of the squares of the Frobenius-to-ℓ₂-norms of all the linear operators contained in the columns of <code>A</code>. If both parameters are omitted, it is calculated automatically; however, this requires memory that scales quartically in the largest side dimension of the <code>A</code> (and may not be supported for all <code>AbstractMatrix</code> types). If both parameters are specified and their values are not consistent, the behavior is undefined.</li></ul><p><strong>Optimization status values</strong></p><ul><li><code>:optimal</code>: the desired accuracy <code>ϵ</code> was reached in both the relative suboptimality gap as well as the relative infeasibility</li><li><code>:max_iter</code>: the maximum number of iterations was reached</li><li><code>:timeout</code>: the maximum computation time was hit</li><li><code>:canceled</code>: the callback returned <code>false</code></li><li><code>:unknown</code>: an internal error has happened</li></ul><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.SketchyCGAL.Status"><code>Status</code></a>.</p><pre><code class="nohighlight hljs">sketchy_cgal(primitive1!, primitive2!, primitive3!, n, b, α; rank, primitive3_norm=0,
    primitive3_normsquare=0, ϵ=1e-8, max_iter=10_000, verbose=false, rescale_C=1,
    rescale_A=[1, ...], rescale_X=1, β₀=1, K=∞, method=:auto, callback=(_) -&gt; ())</code></pre><p>This is the black-box version that allows for matrix-free operations. <code>n</code> is a tuple or vector that indicates the side dimensions of the semidefinite variables, <code>b</code> is the right-hand side of the constraint vector (of length <code>d</code>); and the primitives effectively calculate</p><ul><li><code>primitive1!(v, u, i, α, β) = (v = α * C[i] * u + β * v)</code>, <span>$u, v \in \mathbb R^{n_i}$</span></li><li><code>primitive2!(v, u, z, i, α, β) = (v = α * adjoint(A[:, i])(z) * u + β * v)</code>, <span>$u, v \in \mathbb R^{n_i}$</span>, <span>$z \in \mathbb R^d$</span></li><li><code>primitive3!(v, u, i, α, β) = (v = α * A[:, i](u * u&#39;) + β * v)</code>, <span>$u \in \mathbb R^{n_i}$</span>, <span>$v \in \mathbb R^d$</span></li></ul><p><code>A[:, i](X)</code> is the linear map <code>[⟨X, A[1, i]⟩, ..., ⟨X, A[d, i]⟩]</code> and <code>adjoint(A[:, i])(z) = sum(z[j] * A[j, i])</code>. All of them must also return their outputs (which is <code>v</code>).</p><p>If you are able to calculate these oracles faster or more memory-efficiently than the straightforward implementation (which is based on <code>mul!</code>), use the blackbox method. It is recommended to obey the following normalization conditions:</p><p class="math-container">\[    \sum_i \lVert C_i\rVert_{\mathrm F}^2 = 1;
    \quad
    \sum_i \lVert primitive3!_i\rVert_{\mathrm F \to \ell_2}^2 = 1;
    \quad
    \sum_i \lVert A_{1, i}\rVert^2 = \sum_i \lVert A_{2, i}\rVert^2 = \dotsb\]</p><p>However, in any case, you need to specify the norm of <code>primitive3!</code> (i.e., the supremum of <code>norm(primitive3!)</code> applied to matrices with unit Frobenius norm) in the parameter <code>primitive3_norm</code> (or <code>primitive3_normsquare</code>, which is the sum of the individual normsquares). If the norm is unavailable, you need to at least give a lower bound. You may not specify both parameters inconsistently, else the behavior is undefined. If you had to rescale those matrices in order to achieve this normalization condition, you may pass the corresponding rescaling factors in <code>rescale_C</code> (implying that all <code>C</code> have been scaled by this one factor) and <code>rescale_A</code> (implying that a whole row of <code>A</code> has been scaled by one element from this vector). Additionally, the upper bound in <code>α</code> should be one for a better performance, which is achievable through <code>rescale_X</code> (implying that all <code>X</code> have been scaled by this factor). These are posterior factors that indicate the multiplication that has been done before calling the function in order to enforce compliance. They will be taken into account when calculating the termination criteria (such that <code>ϵ</code> then corresponds to the original problem and not the rescaled one), filling the status structure or verbose output, and the final values of primal objective and optimal <span>$X$</span>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/SketchyCGAL/SketchyCGAL.jl#L37-L132">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.SketchyCGAL.Status" href="#PolynomialOptimization.Solvers.SketchyCGAL.Status"><code>PolynomialOptimization.Solvers.SketchyCGAL.Status</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Status{R}</code></pre><p>This struct contains the current information for the Sketchy CGAL solver. Per-iteration callbacks will receive this structure to gather current information.</p><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.SketchyCGAL.sketchy_cgal"><code>sketchy_cgal</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/SketchyCGAL/SketchyCGAL.jl#L12-L19">source</a></section></article><h2 id="SpecBM"><a class="docs-heading-anchor" href="#SpecBM">SpecBM</a><a id="SpecBM-1"></a><a class="docs-heading-anchor-permalink" href="#SpecBM" title="Permalink"></a></h2><p>While the solver was implemented for the purpose of being used within <code>PolynomialOptimization</code>, it also works as a standalone routine (and could in principle be a separate package). SpecBM is a <a href="https://doi.org/10.48550/arXiv.2307.07651">spectral bundle algorithm for primal semidefinite programs</a> and is based on the assumption that the optimal dual solution has low rank; indeed, in polynomial optimizations, if there is an optimal point for the problem that can be encoded in the chosen basis, then this automatically gives rise to a rank-one semidefinite moment matrix this point. The implementation also allows for free variables and multiple semidefinite constraints and contains further improvements compared to the <a href="https://github.com/soc-ucsd/specBM">reference implementation</a>. It requires either Hypatia or a rather recent version of Mosek (at least 10.1.13) as subsolvers.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.SpecBM.specbm_primal" href="#PolynomialOptimization.Solvers.SpecBM.specbm_primal"><code>PolynomialOptimization.Solvers.SpecBM.specbm_primal</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">specbm_primal(A, b, c; [num_frees,] psds, ρ, r_past, r_current, ϵ=1e-4, β=0.1,
    maxiter=10000, maxnodescent=15, adaptiveρ=false, α=1., adaptiveα=true, αmin=1e-5,
    αmax=1000., ml=0.001, mu=min(1.5β, 1), Nmin=10, verbose=false, step=20, offset=0,
    At=transpose(A), AAt=A*At, [subsolver,]
    callback=(data, mastersolver_data)-&gt;nothing)</code></pre><p>Solves the minimization problem</p><p class="math-container">\[    \min_x \{ ⟨c, x⟩ : A x = b, x = (x_{\mathrm{free}}, \operatorname{svec}(X_1), \dotsc), X_i ⪰ 0,
              \sum_i \operatorname{tr}(X_i) ≤ ρ \} + \mathit{offset}\]</p><p>where the vector <span>$x$</span> contains <code>num_frees</code> free variables, followed by the vectorized and scaled lower triangles of PSD matrices <span>$X_i$</span> that have side dimensions given in <code>psds</code>. <em>Scaled</em> here means that the off-diagonal elements must be multiplied by <span>$\sqrt2$</span> when going from the matrix to its vectorization, so that scalar products are preserved. This corresponds to the <code>:LS</code> format of an <code>SPMatrix</code> from the <a href="https://github.com/projekter/StandardPacked.jl"><code>StandardPacked</code></a> package.</p><p><strong>Arguments</strong></p><p><strong>Problem formulation</strong></p><ul><li><code>A::AbstractMatrix{R}</code>: a sparse or dense matrix</li><li><code>At::AbstractMatrix{R}</code>: the transpose of <code>A</code>. If omitted, <code>transpose(A)</code> is used instead. However, if the transpose is already known in explicit form (in particular, as another <code>SparseMatrixCSC</code>), some operations can be carried out faster.</li><li><code>AAt::AbstractMatrix{R}</code>: the product <code>A*At</code>, which is also calculated automatically, but can be given if it is already known.</li><li><code>b::AbstractVector{R}</code>: a dense or sparse vector</li><li><code>c::AbstractVector{R}</code>: a dense or sparse vector</li><li><code>offset::Real</code>: an offset that is added to the objective</li><li><code>num_frees</code>: the number of free variables in the problem. The first <code>num_frees</code> entries in <span>$x$</span> will be free. If this value is omitted, it is automatically calculated based on the dimensions of <code>A</code> and <code>psds</code>.</li><li><code>psds::AbstractVector{&lt;:Integer}</code>: a vector that, for each semidefinite matrix in the problem, specifies its side dimension. A side dimension of <span>$n$</span> will affect <span>$\frac{n(n +1)}{2}$</span> variables.</li><li><code>ρ::Real</code>: an upper bound on the total trace in the problem. Note that by setting <code>adaptiveρ=true</code>, this bound will effectively be removed by dynamically growing as necessary. In this case, the value specified here is the initial value.</li><li><code>adaptiveρ::Bool</code>: effectively sets <span>$\rho \to \infty$</span>; note that an initial <code>ρ</code> still has to be provided.</li></ul><p><strong>Spectral bundle parameters</strong></p><ul><li><code>r_past::Integer</code>: the number of past eigenvectors to keep, must be nonnegative</li><li><code>r_current::Integer</code>: the number of current eigenvectors to keep, must be positive</li><li><code>β::Real</code>: A step is recognized as a descent step if the decrease in the objective value is at least a factor <span>$\beta \in (0, 1)$</span> smaller than the decrease predicted by the model.</li><li><code>α::Real</code>: the regularization parameter for the augmented Lagrangian; must be positive</li><li><code>adaptiveα::Bool=true</code>: enables adaptive updating of <code>α</code> depending on the following five parameters, as described in <a href="https://doi.org/10.48550/arXiv.2307.07651">Liao et al</a>.</li><li><code>αmin::Real</code>: lower bound for the adaptive algorithm that <code>α</code> may not exceed</li><li><code>αmax::Real</code>: upper bound for the adaptive algorithm that <code>α</code> may not exceed</li><li><code>ml::Real</code>: <code>α</code> is doubled if the decrease in the objective value is at least a factor <span>$m_{\mathrm l} \in (0, \beta)$</span> larger than predicted by the model, provided no descent step was recognized for at least <code>Nmin</code> iterations.</li><li><code>mu::Real</code>: <code>α</code> is halved if the decrease in the objective value is at least a factor <span>$m_{\mathrm u} &gt; \beta$</span> smaller than predicted by the model.</li><li><code>Nmin::Integer</code>: minimum number of no-descent-steps before <code>ml</code> becomes relevant</li><li><code>subsolver::Symbol</code>: subsolver to solve the quadratic semidefinite subproblem in every iteration of SpecBM. Currently, <code>:Hypatia</code> and <code>:Mosek</code> are supported; however, note that Mosek will require at least version 10.1.11 (better 10.1.13 to avoid some rare crashes).</li></ul><p><strong>Termination criteria</strong></p><ul><li><code>ϵ::Real</code>: minimum quality of the result in order for the algorithm to terminate successfully (status <code>:Optimal</code>)</li><li><code>maxiter::Integer</code>: maximum number of iterations before the algorithm terminates anyway (status <code>:IterationLimit</code>). Must be at least <code>2</code>.</li><li><code>maxnodescent::Integer</code>: maximum number of consecutive iterations that may report no descent step before the algorithm terminates (status <code>:SlowProgress</code>). Must be positive or zero to disable this check.</li></ul><p><strong>Logging</strong></p><ul><li><code>verbose::Bool</code>: print the status every <code>step</code> iterations. Note that the first (incomplete) iteration will never be printed.</li><li><code>step::Integer</code>: skip a number of iterations and only print every <code>step</code>th.</li></ul><p><strong>Advanced solver interaction</strong></p><ul><li><code>callback::Function</code>: a callback that is called with the last problem data (type <code>Data</code>) and the last mastersolver data (type <code>MastersolverData</code>) before the mastersolver is called anew. Changes to the structures may be made.</li></ul><p>See also <a href="includedsolvers.html#PolynomialOptimization.Solvers.SpecBM.Result"><code>Result</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/SpecBM/SpecBM.jl#L301-L368">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.SpecBM.Result" href="#PolynomialOptimization.Solvers.SpecBM.Result"><code>PolynomialOptimization.Solvers.SpecBM.Result</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Result</code></pre><p>Contains the result of a SpecBM run</p><p><strong>Fields</strong></p><ul><li><code>status::Symbol</code>: one of <code>:Optimal</code>, <code>:IterationLimit</code>, <code>:SlowProgress</code></li><li><code>objective::R</code>: the objective value</li><li><code>x::Vector{R}</code>: the optimal vector of primal variables: first, <code>num_frees</code> free variables, then all scaled vectorized lower triangles of the PSD variables</li><li><code>y::Vector{R}</code>: the optimal vector of dual variables, one for each constraint</li><li><code>iterations::Int</code>: the number of iterations until the given status was reached</li><li><code>quality::R</code>: the optimality quantifier that is compared against <code>ϵ</code> to determine convergence, which is determined by the maximum of the relative quantities below and the negative primal infeasibility.</li><li><code>primal_infeas::R</code></li><li><code>dual_infeas::R</code></li><li><code>gap::R</code></li><li><code>rel_accuracy::R</code></li><li><code>rel_primal_infeas::R</code></li><li><code>rel_dual_infeas::R</code></li><li><code>rel_gap</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/src/solvers/SpecBM/SpecBM.jl#L263-L284">source</a></section></article><h2 id="LANCELOT"><a class="docs-heading-anchor" href="#LANCELOT">LANCELOT</a><a id="LANCELOT-1"></a><a class="docs-heading-anchor-permalink" href="#LANCELOT" title="Permalink"></a></h2><p><code>PolynomialOptimization</code> provides an interface to LANCELOT. While LANCELOT is part of the <a href="https://github.com/ralna/GALAHAD">GALAHAD</a> library which has a quite recent Julia interface, the LANCELOT part is still pure Fortran without even a C interface. Therefore, here, we exploit that the pre-packaged binaries are compiled with GFortran, version at least 9, so that we know the binary layout of the parameters and can pretend that we like Fortran. Currently, only <code>LANCELOT_simple</code> is supported, which is of course not quite ideal<sup class="footnote-reference"><a id="citeref-7" href="#footnote-7">[7]</a></sup>. Since <code>Galahad.jl</code> is a weak dependency, the package has to be loaded first before the <code>Solvers.LANCELOT</code> module becomes available:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PolynomialOptimization.Solvers.LANCELOT.LANCELOT_simple" href="#PolynomialOptimization.Solvers.LANCELOT.LANCELOT_simple"><code>PolynomialOptimization.Solvers.LANCELOT.LANCELOT_simple</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LANCELOT_simple(n, X, MY_FUN; MY_GRAD=missing, MY_HESS=missing, BL=nothing, BU=nothing,
    neq=0, nin=0, CX=nothing, Y=nothing, maxit=1000, gradtol=1e-5, feastol=1e-5,
    print_level=1)</code></pre><p><strong>Purpose</strong></p><p>A simple and somewhat NAIVE interface to LANCELOT B for solving the nonlinear optimization problem</p><p class="math-container">\[\min_x f(x)\]</p><p>possibly subject to constraints of the one or more of the forms</p><p class="math-container">\[\begin{aligned}
   b_{\mathrm l} &amp; \leq x \leq b_{\mathrm u}, \\
   c_{\mathrm e}( x ) &amp; = 0, \\
   c_{\mathrm i}( x ) &amp; \leq 0
\end{aligned}\]</p><p>where <span>$f\colon \mathbb R^n \to \mathbb R$</span>, <span>$c_{\mathrm e}: \mathbb R^n \to \mathbb R^{n_{\mathrm{eq}}}$</span> and <span>$c_{\mathrm i}\colon \mathbb R^n \to \mathbb R^{n_{\mathrm{in}}}$</span> are twice-continuously differentiable functions.</p><p><strong>Why naive?</strong></p><p>At variance with more elaborate interfaces for LANCELOT, the present one completely <em>ignores underlying partial separability or sparsity structure, restricts the possible forms under which the problem may be presented to the solver, and drastically limits the range of available algorithmic options</em>. If simpler to use than its more elaborate counterparts, it therefore provides a possibly substantially inferior numerical performance, especially for difficult/large problems, where structure exploitation and/or careful selection of algorithmic variants matter.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>The best performance obtainable with LANCELOT B is probably not with the present interface.</p></div></div><p><strong>How to use it?</strong></p><p><strong>Unconstrained problems</strong></p><p>The user should provide, at the very minimum, suitable values for the following input arguments:</p><ul><li><code>n::Integer</code>: the number of variables,</li><li><code>X::AbstractVector{Float64}</code> (strided vector of size <code>n</code>): the starting point for the minimization</li><li><code>MY_FUN</code>: a function for computing the objective function value for any <code>X</code>, whose interface has the default form <code>MY_FUN(X::AbstractVector{Float64})::Float64</code> where <code>X[1:n]</code> contains the values of the variables on input, and which returns a double precision scalar representing the value <span>$f(X)$</span>.</li><li>If the gradient of <span>$f$</span> can be computed, then the (optional) keyword argument <code>MY_GRAD</code> must be specified and given a function computing the gradient, whose interface must be of the form <code>MY_GRAD(G::AbstractVector{Float64}, X::AbstractVector{Float64})</code>, where <code>G</code> is a double precision vector of size <code>n</code> in which the function returns the value of the gradient of <span>$f$</span> at <code>X</code>.</li><li>If, additionally, the second-derivative matrix of <span>$f$</span> at <code>X</code> can be computed, the (optional) keyword argument <code>MY_HESS</code> must be specified and given a function computing the Hessian, whose interface must be of the form <code>MY_HESS(H::SPMatrix{Float64}, X::AbstractVector{Float64})</code>, where <code>H</code> is a double precision symmetrix matrix in packed storage format (upper triangular by column, see the <a href="https://github.com/projekter/StandardPacked.jl"><code>StandardPacked.jl</code></a> package) of the Hessian of <span>$f$</span> at <code>X</code>.</li></ul><p>In all cases, the best value of <span>$x$</span> found by LANCELOT B is returned to the user in the vector <code>X</code> and the associated objective function value is the first return value. The second return value reports the number of iterations performed by LANCELOT before exiting. Finally, the last return value contains the exit status of the LANCELOT run, the value <code>0</code> indicating a successful run. Other values indicate errors in the input or unsuccessful runs, and are detailed in the specsheet of LANCELOT B (with the exception of the value 19, which reports a negative value for one or both input arguments <code>nin</code> and <code>neq</code>).</p><p><strong>Example</strong></p><p>Let us consider the optimization problem</p><p class="math-container">\[\min_{x_1, x_2} f(x_1, x_2) = 100 ( x_2 - x_1^2 )^2 + ( 1 - x_1 )^2\]</p><p>which is the ever-famous Rosenbrock &quot;banana&quot; problem. The most basic way to solve the problem (but NOT the most efficient) is, assuming the starting point <code>X = [-1.2, 1.]</code> known, to perform the call <code>PolynomialOptimization.LANCELOT_simple(2, X, FUN)</code> where the user-provided function <code>FUN</code> is given by</p><pre><code class="language-julia hljs">FUN(X) = @inbounds 100 * (X[2] - X[1]^2)^2 + (1 - X[1])^2</code></pre><p>The solution is returned in 60 iterations with exit code <code>0</code>.</p><p>If we now wish to use first and second derivatives of the objective function, one should use the call</p><pre><code class="language-julia hljs">PolynomialOptimization.LANCELOT_simple(2, X, FUN, MY_GRAD=GRAD!, MY_HESS=HESS!)</code></pre><p>and provide the additional routines</p><pre><code class="language-julia hljs">GRAD!(G, X) = @inbounds begin
    G[1] = -400 * (X[2] - X[1]^2) * X[1] - 2 * (1 - X[1])
    G[2] = 200 * (X[2] - X[1]^2)
end

HESS!(H, X) = @inbounds begin
    H[1, 1] = -400 * (X[2] - 3 * X[1]^2) + 2
    H[1, 2] = -400 * X[1]
    H[2, 2] = 200
end</code></pre><p>Convergence is then obtained in 23 iterations. Note that using exact first-derivatives only is also possible: <code>MY_HESS</code> should then be absent from the calling sequence and providing the subroutine <code>HESS!</code> unnecessary.</p><p><strong>Bound constrained problems</strong></p><p>Bound on the problem variables may be imposed by specifying one or both of</p><ul><li><code>BL::AbstractVector{Float64}</code> (double precision vector of size <code>n</code>): the lower bounds on <code>X</code>,</li><li><code>BU::AbstractVector{Float64}</code> (double precision vector of size <code>n</code>): the upper bounds on <code>X</code>.</li></ul><p>Note that infinite bounds (represented by a number larger than <code>1e20</code> in absolute value) are acceptable, as well as equal lower and upper bounds, which amounts to fixing the corresponding variables. Except for the specification of <code>BL</code> and/or <code>BU</code>, the interface is identical to that for unconstrained problems.</p><p><strong>Example</strong></p><p>If one now wishes to impose zero upper bounds on the variables of our unconstrained problem, one could use the following call</p><pre><code class="language-julia hljs">PolynomialOptimization.LANCELOT_simple(2, X, FUN, MY_GRAD=GRAD!, MY_HESS=HESS!,
    BU=zeros(2))</code></pre><p>in which case convergence is obtained in 6 iterations.</p><p><strong>Equality constrained problems</strong></p><p>If, additionally, general equality constraints are also present in the problem, this must be declared by specifying the following (optional) input argument:</p><ul><li><code>neq::Integer</code>: the number of equality constraints.</li></ul><p>In this case, the equality constraints are numbered from 1 to <code>neq</code> and the value of the <code>i</code>-th equality constraint must be computed by a user-supplied routine of the form <code>FUN(X, i)</code> (with <code>i = 1, ..., neq</code>) where the function now returns the value of the <code>i</code>-th equality constraint evaluated at <code>X</code> if <code>i</code> is specified. (This extension of the unconstrained case can be implemented by adding an optional argument <code>i</code> to the unconstrained version of <code>FUN</code> or by defining a three-parameter method on its own.) If derivatives are available, then the <code>MY_GRAD</code> and <code>MY_HESS</code> subroutines must be adapted as well: <code>MY_GRAD(G, X, i)</code> and <code>MY_HESS(H, X, i)</code> for computing the gradient and Hessian of the <code>i</code>-th constraint at <code>X</code>. Note that, if the gradient of the objective function is available, so must be the gradients of the equality constraints. The same level of derivative availability is assumed for all problem functions (objective and constraints). The final values of the constraints and the values of their associated Lagrange multipliers is optionally returned to the user in the (optional) double precision keyword arguments <code>CX</code> and <code>Y</code>, respectively (both being of size <code>neq</code>).</p><p><strong>Inequality constrained problems</strong></p><p>If inequality constraints are present in the problem, their inclusion is similar to that of equality constraints. One then needs to specify the (optional) input argument</p><ul><li><code>nin::Integer</code>: the number of inequality constraints.</li></ul><p>The inequality constraints are then numbered from <code>neq+1</code> to <code>neq+nin</code> and their values or that of their derivatives is again computed by calling, for <code>i = 1, ..., nin</code>, <code>FUN(X, i)</code>, <code>MY_GRAD(G, X, i)</code>, <code>MY_HESS(H, X, i)</code>. The inequality constraints are internally converted in equality ones by the addition of a slack variables, whose names are set to &#39;Slack_<code>i</code>&#39;, where the character <code>i</code> in this string takes the integers values <code>1</code> to <code>nin</code>. The values of the inequality constraints at the final <code>X</code> are finally returned (as for equalities) in the optional double precision keyword argument <code>CX</code> of size <code>nin</code>. The values of the Lagrange multipliers are returned in the optional double precision output argument <code>Y</code> of size <code>nin</code>.</p><p><strong>Problems with equality and inequality constraints</strong></p><p>If they are both equalities and inequalities, <code>neq</code> and <code>nin</code> must be specified and the values and derivatives of the constraints are computed by <code>FUN(X, i)</code>, <code>GRAD(G, X, i)</code>, <code>HESS(H, X, i)</code> (<code>i = 1, ..., neq</code>) for the equality constraints, and <code>FUN(X, i)</code>, <code>GRAD(G, X, i)</code>, <code>HESS(H, X, i)</code> (<code>i = neq+1, ..., neq+nin</code>) for the inequality constraints. Again, the same level of derivative availability is assumed for all problem functions (objective and constraints). Finally, the optional arguments <code>CX</code> and/or <code>Y</code>, if used, are then of size <code>neq+nin</code>.</p><p><strong>Example</strong></p><p>If we now wish the add to the unconstrained version the new constraints</p><p class="math-container">\[\begin{aligned}
    0 &amp; \leq x_1 \\
    x_1 + 3x_2 - 3 &amp; = 0 \\
    x_1^2 + x_2^2 - 4 &amp; \leq 0,
\end{aligned}\]</p><p>we may transform our call to</p><pre><code class="language-julia hljs">CX = Vector{Float64}(undef, 2)
Y = Vector{Float64}(undef, 2)
LANCELOT_simple(2, X, FUN; MY_GRAD=GRAD!, MY_HESS=HESS!, BL=[0., -1e20], neq=1, nin=1,
    CX, Y)</code></pre><p>(assuming we need <code>CX</code> and <code>Y</code>), and add methods for <code>FUN</code>, <code>GRAD!</code> and <code>HESS!</code> as follows</p><pre><code class="language-julia hljs">FUN(X, i) = @inbounds begin
    if i == 1 # the equality constraint
        return X[1] + 3X[2] - 3
    elseif i == 2 # the inequality constraint
        return X[1]^2 + X[2]^2 - 4
    end
    return NaN # should never happen
end

GRAD!(G, X, i) = @inbounds begin
    if i == 1 # equality constraint&#39;s gradient components
        G[1] = 1
        G[2] = 3
    elseif i == 2 # inequality constraint&#39;s gradient components
        G[1] = 2X[1]
        G[2] = 2X[2]
    end
    return
end

HESS!(H, X, i) = @inbounds begin
    if i == 1 # equality constraint&#39;s Hessian
        fill!(H, 1.)
    elseif i == 2 # inequality constraint&#39;s Hessian
        H[1] = 2
        H[2] = 0
        H[3] = 2
    end
    return
end</code></pre><p>Convergence is then obtained in 8 iterations. Note that, in our example, the objective function or its derivatives is/are computed if the index <code>i</code> is omitted (see above). Of course, the above examples can easily be modified to represent new minimization problems :-).</p><p><strong>Available algorithmic options</strong></p><p>Beyond the choice of derivative level for the problem functions, the following arguments allow a (very limited) control of the algorithmic choices used in LANCELOT.</p><ul><li><code>maxit::Integer</code>: maximum number of iterations (default: <code>1000</code>)</li><li><code>gradtol::Real</code>: the threshold on the infinity norm of the gradient (or of the lagrangian&#39;s gradient) for declaring convergence  (default: <code>1.0e-5</code>)</li><li><code>feastol::Real</code>: the threshold on the infinity norm of the constraint violation for declaring convergence (for constrained problems) (default: <code>1.0e-5</code>)</li><li><code>print_level::Integer</code>: a positive number proportional to the amount of output by the package: <code>0</code> corresponds to the silent mode, <code>1</code> to a single line of information per iteration (default), while higher values progressively produce more output.</li></ul><p><strong>Other sources</strong></p><p>The user is encouraged to consult the specsheet of the (non-naive) interface to LANCELOT within the GALAHAD software library for a better view of all possibilities offered by an intelligent use of the package. The library is described in the paper</p><pre><code class="nohighlight hljs">N. I. M. Gould, D. Orban, Ph. L. Toint,
GALAHAD, a library of thread-sage Fortran 90 packages for large-scale
nonlinear optimization,
Transactions of the AMS on Mathematical Software, vol 29(4),
pp. 353-372, 2003</code></pre><p>The book</p><pre><code class="nohighlight hljs">A. R. Conn, N. I. M. Gould, Ph. L. Toint,
LANCELOT, A Fortan Package for Large-Scale Nonlinear Optimization
(Release A),
Springer Verlag, Heidelberg, 1992</code></pre><p>is also a good source of additional information.</p><p>Main author: Ph. Toint, November 2007. Copyright reserved, Gould/Orban/Toint, for GALAHAD productions</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/projekter/PolynomialOptimization.jl/blob/fd67bd1ae5324788e591b9bb3be4e194ec2d5f93/ext/PolynomialOptimizationLancelot/Bindings.jl#L6-L237">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Note that by default, a sparse solver is used (unless the problem was constructed with a <code>factor_coercive</code> different from   one). This is typically a good idea for large systems with not too much monomials. However, if you have a very dense   system, the sparse solver will take forever; better pass <code>dense=true</code> to the optimization routine. This will then be much   faster (and always much more accurate).</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>LANCELOT is a nonlinear solver that directly works on the problem itself. It does not use a relaxation. Therefore, it   cannot provide lower-bound guarantees on the objective value; however, there is no problem with the extraction of a   solution, as the solver directly works on the decision variables. When invoking the LANCELOT solver, a function is   returned which performs the optimization and which requires a vector of initial values as parameter. This function will   then return a 2-tuple with the (locally) optimal objective value and the point of the local optimum.   Currently, the LANCELOT interface does not support complex-valued problems.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>There is a separate <a href="https://github.com/kocvara/Loraine.jl">Julia package for Loraine</a>. However, the implementation is so   bad that it is not only unnecessarily inefficient, but would also not allow to solve large-scale systems. Therefore,   <code>PolynomialOptimization</code> provides a rewritten implementation, which is heavily based on the original source code, but   tries to use the available memory more efficiently (though there is still room for improvement). Since only a subset of   the features of the original package has been implemented, this is not yet ready to be contributed to the solver; but it   can be expected that in the future, an external package will be required to use Loraine.</li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a>There is no Julia package for LoRADS available. You first have to clone the linked Git repositiory and compile the solver   for your system; then, call <a href="includedsolvers.html#PolynomialOptimization.Solvers.LoRADS.set_solverlib"><code>Solvers.LoRADS.set_solverlib</code></a> in order to tell <code>PolynomialOptimization</code> where to   look for the binary. After restarting Julia, the method is available.</li><li class="footnote" id="footnote-5"><a class="tag is-link" href="#citeref-5">5</a><code>:MosekMoment</code> requires at least version 10, <code>:MosekSOS</code> already works with version 9.   The moment variant is more prone to failure in case of close-to-illposed problems; sometimes, this is an issue of the   presolver, which can be turned off by passing <code>MSK_IPAR_PRESOLVE_USE=&quot;MSK_PRESOLVE_MODE_OFF&quot;</code> to <a href="backend.html#PolynomialOptimization.Solver.poly_optimize-Tuple{Val, PolynomialOptimization.Relaxation.AbstractRelaxation, PolynomialOptimization.Relaxation.RelaxationGroupings}-backend"><code>poly_optimize</code></a>.   The performance indicators in the table are valid for <code>:MosekSOS</code>. The new PSD cone interface of Mosek 10 that is used by   the moment-based variant proves to be much slower than the old one; therefore, using <code>:MosekMoment</code> is not recommended.</li><li class="footnote" id="footnote-6"><a class="tag is-link" href="#citeref-6">6</a><code>SpecBM</code> is provided by <code>PolynomialOptimization</code>; however, it requires a subsolver for the quadratic master problem.   Currently, <code>Mosek</code> and <code>Hypatia</code> are implemented and must therefore be loaded to make <code>SpecBM</code> work.</li><li class="footnote" id="footnote-7"><a class="tag is-link" href="#citeref-7">7</a>The branch <code>lancelot</code> goes further and defines an interface for the full version of LANCELOT, which is a lot more   sophisticated. Unfortunately, it also seems to be broken at the moment and bugfixing will require some debugging of the   disassembly. This is not a priority at the moment (which is whenever you read this statement).</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="reference.html">« Reference</a><a class="docs-footer-nextpage" href="backend.html">Backend »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.10.1 on <span class="colophon-date" title="Tuesday 1 April 2025 15:45">Tuesday 1 April 2025</span>. Using Julia version 1.10.9.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
